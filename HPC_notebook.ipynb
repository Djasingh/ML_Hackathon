{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eccf2af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 17:52:14.240757: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-28 17:52:14.997460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from transformers import AutoTokenizer, TFBertModel\n",
    "from transformers import AutoTokenizer, BertModel,BertForSequenceClassification\n",
    "from transformers import DistilBertForSequenceClassification,Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "026e6071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(filename=\"Doceree-HCP_Train.csv\"):\n",
    "    data =  pd.read_csv(filename,encoding='latin-1')\n",
    "    if \"IS_HCP\" in data.columns:\n",
    "        data = data[data[\"IS_HCP\"].isin([0,1])]\n",
    "    data[\"text_info\"] = (data[\"KEYWORDS\"].astype(str)+\" \"+\n",
    "                         data[\"USERCITY\"].astype(str)+\" \"+\n",
    "                         data[\"DEVICETYPE\"].astype(str)+\" \"+\n",
    "                         data[\"CHANNELTYPE\"].astype(str)+\" \"+\n",
    "                         data[\"USERAGENT\"].astype(str)+\" \"+\n",
    "                         data[\"URL\"].astype(str)+\" \"+\n",
    "                         data[\"PLATFORMTYPE\"].astype(str)\n",
    "                        )\n",
    "\n",
    "    #data[\"TAXONOMY\"].astype(str)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1398ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(input_text, tokenizer):\n",
    "  '''\n",
    "  Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
    "    - input_ids: list of token ids\n",
    "    - token_type_ids: list of token type ids\n",
    "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
    "  '''\n",
    "  return tokenizer.encode_plus(\n",
    "                        input_text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 512,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt'\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28d7881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (113936, 15)\n",
      "test size: (28493, 13)\n"
     ]
    }
   ],
   "source": [
    "train_data = data(\"Doceree-HCP_Train.csv\")\n",
    "test_data  = data(\"Doceree-HCP_Test.csv\")\n",
    "print(f\"train size: {train_data.shape}\")\n",
    "print(f\"test size: {test_data.shape}\")\n",
    "\n",
    "train_texts  = list(train_data[\"text_info\"].values)\n",
    "train_labels = [int(i) for i in train_data[\"IS_HCP\"].values]\n",
    "\n",
    "train_labels = OneHotEncoder().fit_transform(np.array(train_labels).reshape(-1,1)).toarray()\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "739370d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/dhananjay/Competition/venv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "#model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "train_token_id = []\n",
    "train_attention_masks = []\n",
    "for sample in train_texts:\n",
    "    train_encoding_dict = preprocessing(sample, tokenizer)\n",
    "    train_token_id.append(train_encoding_dict['input_ids']) \n",
    "    train_attention_masks.append(train_encoding_dict['attention_mask'])\n",
    "train_token_id = torch.cat(train_token_id, dim = 0)\n",
    "train_attention_masks = torch.cat(train_attention_masks, dim = 0)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "\n",
    "\n",
    "val_token_id = []\n",
    "val_attention_masks = []\n",
    "for sample in val_texts:\n",
    "    val_encoding_dict = preprocessing(sample, tokenizer)\n",
    "    val_token_id.append(val_encoding_dict['input_ids']) \n",
    "    val_attention_masks.append(val_encoding_dict['attention_mask'])\n",
    "val_token_id = torch.cat(val_token_id, dim = 0)\n",
    "val_attention_masks = torch.cat(val_attention_masks, dim = 0)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "# train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_)\n",
    "# val_encodings   = tokenizer(val_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58504c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb0bc2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HCPDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, token_id, attention_masks, labels):\n",
    "        self.token_id = token_id\n",
    "        self.attention_masks = attention_masks\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item={}\n",
    "        item[\"input_ids\"] = self.token_id[idx]\n",
    "        item[\"attention_mask\"] = self.attention_masks[idx]\n",
    "        item['labels'] = self.labels[idx].to(torch.float32)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = HCPDataset(train_token_id, train_attention_masks, train_labels)\n",
    "val_dataset = HCPDataset(val_token_id, val_attention_masks, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc684a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset.encodings.data[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52eb8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset.labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba72cce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2, output_attentions= False, output_hidden_states = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cce7e59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhananjay/Competition/venv/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5697' max='5697' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5697/5697 1:13:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.441900</td>\n",
       "      <td>0.238360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.170450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.118500</td>\n",
       "      <td>0.073048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.082108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.071800</td>\n",
       "      <td>0.045861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.046410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.034680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.033316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.033801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.032983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.025399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5697, training_loss=0.10182869382044381, metrics={'train_runtime': 4397.1166, 'train_samples_per_second': 20.729, 'train_steps_per_second': 1.296, 'total_flos': 1.2074138452697088e+16, 'train_loss': 0.10182869382044381, 'epoch': 1.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\")\n",
    "num_labels = 2,\n",
    "    \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results1',          \n",
    "    num_train_epochs=1,              \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=64,   \n",
    "    warmup_steps=500,               \n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    # strength of weight decay\n",
    "    #logging_dir='./logs1',            \n",
    "    #logging_steps=1000,\n",
    "    save_total_limit = 2,\n",
    "    load_best_model_at_end=False,\n",
    "    save_strategy = \"no\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=val_dataset             \n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d165ea95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='357' max='357' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [357/357 03:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.02367251180112362,\n",
       " 'eval_runtime': 180.0483,\n",
       " 'eval_samples_per_second': 126.566,\n",
       " 'eval_steps_per_second': 1.983,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4534fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"./HPC_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fe97404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./HPC_model/tokenizer_config.json',\n",
       " './HPC_model/special_tokens_map.json',\n",
       " './HPC_model/vocab.txt',\n",
       " './HPC_model/added_tokens.json',\n",
       " './HPC_model/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trainer.save_model(output_dir=\"HPC_model1\")\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10df9d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= DistilBertForSequenceClassification.from_pretrained(save_directory)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c91e7508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"_name_or_path\": \"HPC_model1\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"problem_type\": \"multi_label_classification\",\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.30.2\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e21673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#model.to(device)\n",
    "test_texts =list(test_data[\"text_info\"].values)\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "test_output = []\n",
    "for i in range(0,len(test_texts),batch_size):\n",
    "    test_ids = []\n",
    "    test_attention_mask = []\n",
    "    for sample in test_texts[i:i+batch_size]:\n",
    "        encoding = preprocessing(sample, tokenizer)\n",
    "        test_ids.append(encoding['input_ids']) \n",
    "        test_attention_mask.append(encoding['attention_mask'])\n",
    "\n",
    "\n",
    "   \n",
    "    test_ids = torch.cat(test_ids, dim = 0)\n",
    "    test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
    "\n",
    "    # Forward pass, calculate logit predictions\n",
    "    with torch.no_grad():\n",
    "        output = model(test_ids.to(device),attention_mask = test_attention_mask.to(device))\n",
    "        test_output.append(output.logits.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01948cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = np.concatenate(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcecaf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_f = np.argmax(test_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9026ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28493,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bccb1929",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"IS_HCP\"]= test_predict_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "241f5689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DEVICETYPE</th>\n",
       "      <th>PLATFORM_ID</th>\n",
       "      <th>BIDREQUESTIP</th>\n",
       "      <th>USERPLATFORMUID</th>\n",
       "      <th>USERCITY</th>\n",
       "      <th>USERZIPCODE</th>\n",
       "      <th>USERAGENT</th>\n",
       "      <th>PLATFORMTYPE</th>\n",
       "      <th>CHANNELTYPE</th>\n",
       "      <th>URL</th>\n",
       "      <th>KEYWORDS</th>\n",
       "      <th>text_info</th>\n",
       "      <th>IS_HCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115501</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>75.189.231.103</td>\n",
       "      <td>0d5041ff-f0b6-4d1a-9ad7-0a29f7d485b4</td>\n",
       "      <td>Fayetteville</td>\n",
       "      <td>28305.0</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6...</td>\n",
       "      <td>Online Medical Journal</td>\n",
       "      <td>Website</td>\n",
       "      <td>https://www.clinicaladvisor.com/home/features/...</td>\n",
       "      <td>Family Practice|Drainage|Clinical|Dermatology|...</td>\n",
       "      <td>Family Practice|Drainage|Clinical|Dermatology|...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115502</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>2</td>\n",
       "      <td>24.101.33.158</td>\n",
       "      <td>c8396dd0-969f-4d99-a40b-b7bb1f516154</td>\n",
       "      <td>Conneaut Lake</td>\n",
       "      <td>16316.0</td>\n",
       "      <td>Mozilla/5.0 (iPhone; CPU iPhone OS 15_6_1 like...</td>\n",
       "      <td>Online Medical Journal</td>\n",
       "      <td>Website</td>\n",
       "      <td>https://www.ophthalmologyadvisor.com/topics/ca...</td>\n",
       "      <td>General|Clinical|Operative|Medicine|Cardiology...</td>\n",
       "      <td>General|Clinical|Operative|Medicine|Cardiology...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115503</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>172.118.216.142</td>\n",
       "      <td>3c97a081-6518-43f8-9f26-369759cfb471</td>\n",
       "      <td>Covina</td>\n",
       "      <td>91724.0</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...</td>\n",
       "      <td>Online Medical Journal</td>\n",
       "      <td>Website</td>\n",
       "      <td>https://www.psychiatryadvisor.com/author/tori-...</td>\n",
       "      <td>Abortion|Anxiety Disorders|Apnea|False|Trauma|...</td>\n",
       "      <td>Abortion|Anxiety Disorders|Apnea|False|Trauma|...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115504</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>7</td>\n",
       "      <td>71.105.120.171</td>\n",
       "      <td>3e2578c8-f794-41af-a38c-c5cfb3c0f014</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...</td>\n",
       "      <td>Online Medical Journal</td>\n",
       "      <td>Website</td>\n",
       "      <td>https://www.cureus.com/articles/105482-diverti...</td>\n",
       "      <td>Health|Male|Neurological Surgery|Otolaryngolog...</td>\n",
       "      <td>Health|Male|Neurological Surgery|Otolaryngolog...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115505</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>2</td>\n",
       "      <td>73.82.211.73</td>\n",
       "      <td>ec2ae7ce-6a8c-4156-98a7-07203e60f483</td>\n",
       "      <td>Marietta</td>\n",
       "      <td>30062.0</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...</td>\n",
       "      <td>Online Medical Journal</td>\n",
       "      <td>Website</td>\n",
       "      <td>https://www.renalandurologynews.com/home/confe...</td>\n",
       "      <td>chronic kidney disease|pain|nephrology|disease...</td>\n",
       "      <td>chronic kidney disease|pain|nephrology|disease...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID DEVICETYPE  PLATFORM_ID     BIDREQUESTIP  \\\n",
       "0  115501    Desktop            2   75.189.231.103   \n",
       "1  115502     Mobile            2    24.101.33.158   \n",
       "2  115503    Desktop            2  172.118.216.142   \n",
       "3  115504    Desktop            7   71.105.120.171   \n",
       "4  115505    Desktop            2     73.82.211.73   \n",
       "\n",
       "                        USERPLATFORMUID       USERCITY  USERZIPCODE  \\\n",
       "0  0d5041ff-f0b6-4d1a-9ad7-0a29f7d485b4   Fayetteville      28305.0   \n",
       "1  c8396dd0-969f-4d99-a40b-b7bb1f516154  Conneaut Lake      16316.0   \n",
       "2  3c97a081-6518-43f8-9f26-369759cfb471         Covina      91724.0   \n",
       "3  3e2578c8-f794-41af-a38c-c5cfb3c0f014       Brooklyn      11226.0   \n",
       "4  ec2ae7ce-6a8c-4156-98a7-07203e60f483       Marietta      30062.0   \n",
       "\n",
       "                                           USERAGENT            PLATFORMTYPE  \\\n",
       "0  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6...  Online Medical Journal   \n",
       "1  Mozilla/5.0 (iPhone; CPU iPhone OS 15_6_1 like...  Online Medical Journal   \n",
       "2  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...  Online Medical Journal   \n",
       "3  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7...  Online Medical Journal   \n",
       "4  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...  Online Medical Journal   \n",
       "\n",
       "  CHANNELTYPE                                                URL  \\\n",
       "0     Website  https://www.clinicaladvisor.com/home/features/...   \n",
       "1     Website  https://www.ophthalmologyadvisor.com/topics/ca...   \n",
       "2     Website  https://www.psychiatryadvisor.com/author/tori-...   \n",
       "3     Website  https://www.cureus.com/articles/105482-diverti...   \n",
       "4     Website  https://www.renalandurologynews.com/home/confe...   \n",
       "\n",
       "                                            KEYWORDS  \\\n",
       "0  Family Practice|Drainage|Clinical|Dermatology|...   \n",
       "1  General|Clinical|Operative|Medicine|Cardiology...   \n",
       "2  Abortion|Anxiety Disorders|Apnea|False|Trauma|...   \n",
       "3  Health|Male|Neurological Surgery|Otolaryngolog...   \n",
       "4  chronic kidney disease|pain|nephrology|disease...   \n",
       "\n",
       "                                           text_info  IS_HCP  \n",
       "0  Family Practice|Drainage|Clinical|Dermatology|...       0  \n",
       "1  General|Clinical|Operative|Medicine|Cardiology...       1  \n",
       "2  Abortion|Anxiety Disorders|Apnea|False|Trauma|...       0  \n",
       "3  Health|Male|Neurological Surgery|Otolaryngolog...       0  \n",
       "4  chronic kidney disease|pain|nephrology|disease...       1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d5f1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_data[[\"ID\",\"IS_HCP\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4761070",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"Doceree-HCP_Submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07c2de13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>IS_HCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115501</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>115506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>115507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>115508</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>115509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>115510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  IS_HCP\n",
       "0  115501       0\n",
       "1  115502       1\n",
       "2  115503       0\n",
       "3  115504       0\n",
       "4  115505       1\n",
       "5  115506       0\n",
       "6  115507       0\n",
       "7  115508       0\n",
       "8  115509       0\n",
       "9  115510       0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127fdcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
